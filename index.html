
<!DOCTYPE html>
<html>
<head>
  <title>MMT-Bench</title>
    <style>
        .hidden {
            display: none;
        }
    </style>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://kit.fontawesome.com/f8ddf9854a.js" crossorigin="anonymous"></script>
  <meta charset="utf-8">
  <meta name="description"
        content="A Multimodal MultiTask Benchmark for Comprehensive Evaluation of Large Vision-Language Models">
  <meta name="keywords" content="MMT-Bench, LVLM, LVLM Evaluation, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> MMT-Bench: A Multimodal MultiTask Benchmark for Comprehensive Evaluation of Large Vision-Language Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/question_card.js"></script>
  <script src="./data/results/data_setting.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>
  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/OpenGVLab/Multi-Modality-Arena">
            <b>Lvlm-ehub</b> <p style="font-size:18px; display: inline; margin-left: 5px;">🔥</p>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <span class="MMT-Bench" style="vertical-align: middle">MMT-Bench</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            A Multimodal MultiTask Benchmark for Comprehensive 
            <!-- <br> -->
            Evaluation of Large Vision-Language Models
          </h2>
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block">Xiang Yue*<sup style="color:#6fbf73;">†,1</sup>,</span> -->
            <span class="author-block">
              Kaining Ying<sup>*,</sup><sup style="color:#6fbf73;">1</sup></a>,
            </span>
            <span class="author-block">
              Fanqing Meng<sup>*,</sup><sup style="color:#ffac33;">2</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
            </span>
            <!-- <span class="author-block">Yuansheng Ni*<sup style="color:#ffac33;">2</sup>,</span> -->
            <span class="author-block">
              Jin Wang<sup>*,</sup><sup style="color:#ed4b82;">3</sup></a>
              ,
            </span>
            <!-- <span class="author-block">Kai Zhang*<sup style="color:#ed4b82;">3</sup>,</span> -->
            <span class="author-block">Zhiqian Li<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ed4b82;">3</sup></span>
            <span class="author-block">Han Lin<sup style="color:#ffac33;">2</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></span>
            <span class="author-block">Yue Yang<sup style="color:#ffac33;">2</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Hao Zhang<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Wenbo Zhang<sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Yuqi Lin<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#9b51e0;">5</sup>,</span>
            <span class="author-block">Shuo Liu<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Jiayi Lei<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Quanfeng Lu<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Runjian Chen<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Peng Xu<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Renrui Zhang<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Haozhe Zhang<sup style="color:#9b51e0;">5</sup>,</span>
            <span class="author-block">Peng Gao<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Yali Wang<sup style="color:#1b1be0;">6</sup>,</span>
            <span class="author-block">Yu Qiao<sup style="color:#6fbf73;">1</sup>,</span><br>
            <!-- <span class="author-block">Huan Sun*<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Yu Su*<sup style="color:#ed4b82;">†,3</sup>,</span>
            <span class="author-block">Wenhu Chen*<sup style="color:#ffac33;">†,2</sup></span> -->
            <span class="author-block">
              Ping Luo<sup style="color:#ed4b82;">3</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
          </span>
          <span class="author-block">
              Kaipeng Zhang<sup>†,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
          </span>
          <span class="author-block">
              Wenqi Shao<sup>†,</sup><sup style="color:#6fbf73;">1</sup></a>
              
          </span>
          
          </div>
          
          <br>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>Shanghai Artificial Intelligence Laboratory,</span>
            <span class="author-block"><sup style="color:#ffac33;">2</sup>Shanghai Jiao Tong University,</span></br>
            <span class="author-block"><sup style="color:#ed4b82;">3</sup>The University of Hong Kong,</span>
            <span class="author-block"><sup style="color:#007bff;">4</sup>The University of Adelaide,</span></br>
            <span class="author-block"><sup style="color:#9b51e0;">5</sup>Zhejiang University,</span>
            <span class="author-block"><sup style="color:#1b1be0;">6</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences,</span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution</span><br>
            <span class="author-block">†Corresponding Author:</span>
            <span class="author-block"><a href="mailto:shaowenqi@pjlab.org.cn">shaowenqi@pjlab.org.cn</a>,</span>
            <span class="author-block"><a href="mailto:zhangkaipeng@pjlab.org.cn">zhangkaipeng@pjlab.org.cn</a></span>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/pdf/2404.16006.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/Kaining/MMT-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">🤗</p>
                      <!-- 🔗 -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/OpenGVLab/MMT-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-trophy"></i>
                      <!-- <p style="font-size:18px">🏆</p> -->
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
              <!-- EvalAI Link. -->
              <span class="link-block">
                <a href="#examples"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-book"></i>
                  </span>
                  <span>Examples</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<style>
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }
</style>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body">
      <img src="static/images/tease_scores.png" alt="Examples from the dataset"/>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div> -->
      <!-- <div class="box m-5"> -->
        <div class="content has-text-centered">
          <img src="static/images/overview_mmtbench.png" alt="MMT-bench" width="100%"/>
          <p> Visualization of MMT-Bench. Our MMT-Bench consists of 32 meta-tasks (middle ring) which are decomposed into 162 subtasks (outer ring). For each meta-task, we denote the number of subtasks in it and illustrate one example of the pair of the image
            and the question. MMT-Bench can be comprehensive enough to evaluate the multitask performance of LVLMs.</p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">🔔News</h2>
        <div class="content has-text-justified">
          <p>
            <b>🔥[2024-04-26]: We release our code! Stay tuned!</b>
          </p>
          <p>
            <b>🔥[2024-04-25]: We release our paper! Stay tuned!</b>
          </p>
      </div>      
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            We present MMT-Bench, a comprehensive benchmark designed to assess LVLMs across massive multimodal tasks requiring expert knowledge and deliberate visual recognition, localization, reasoning, and planning. MMT-Bench comprises <b>31,325</b> meticulously curated multi-choice visual questions from various multimodal scenarios such as vehicle driving and embodied navigation, covering <b>32</b> core meta-tasks and <b>162</b> subtasks in multimodal understanding. Due to its extensive task coverage, MMT-Bench enables the evaluation of LVLMs using a task map, facilitating the discovery of in- and out-of-domain tasks. Evaluation results involving <b>30</b> LVLMs such as the proprietary GPT-4V, GeminiProVision, and open-sourced InternVL-Chat, underscore the significant challenges posed by MMT-Bench. We anticipate that MMT-Bench will inspire the community to develop next-generation multimodal foundation models aimed at achieving general-purpose multimodal intelligence.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 MMT-bench">
    <span class="MMT-bench" style="vertical-align: middle">MMT-Bench</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="static/images/task2.png" alt="pipeline" class="center">
          <br>
          <p>
            An illustration of our pipeline for data collection. First, given a task name, we retrieve its related datasets from the internet.
            Then we collate them in a uniform data format - metadata. Finally, we generate questions with choices and answers from metadata using
            manually designed rules or ChatGPT. Our benchmarks cover capabilities evaluation with diverse image types
          </p>
        </div>
    </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparisons with Existing Benchmarks</h2>
        <div class="content has-text-justified">
          <p>
            MMT-Bench consists of massive samples and multimodal tasks compared with other benchmarks. I, T, V, and P respectively represent image, text, video, and point cloud. 
            Compared with previous benchmarks, MMT-Bench covers an extensive range of multimodal reasoning capabilities with sufficient test samples from various modalities, which requires expert knowledge and deliberate visual recognition, localization, reasoning, and planning. Our MMT-Bench poses significant challenges for the current state-of-the-art LVLMs.
        </p>
        <img src="static/images/compare.png" alt="comparison" class="center">
        </div>
    </div>
    </div>
  </div>
</section>

<style>
  .image-row {
      display: center; /* Use flexbox layout */
  }
  .image-row img {
      width: 40%; /* Each image takes up 50% of the width */
  }
</style>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 MMT-Bench">Experiment Results</h1>
  </div>
</section>
<section class="section">
  <div class="container">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <div class="content has-text-justified">
            <p>
              Quantitative results for <b>30</b> LVLMs across <b>32</b> meta-tasks are summarized, with <span style="text-decoration: overline;"><strong>R</strong></span> representing the average rank. Accuracy is the metric, and the Overall score is computed across all subtasks, excluding visual recognition (VR) as denoted by <strong>*</strong>. 
              The maximum value of each meta-task is <b>bolded</b>. Meta-tasks are abbreviated for brevity, with full terms in the paper for reference.
            </p>
          </div>

          <div class="model-labels-container">
            <!-- <span class="leaderboard-label" style="background-color: #f8fffe;">Open-Source</span>
            <span class="leaderboard-label" style="background-color: #f9f2f8;">Closed</span> -->

            <span class="leaderboard-label" style="background-color: rgba(255, 208, 80, 0.15);">Baseline</span>
            <span class="leaderboard-label" style="background-color: rgba(249, 242, 248, 1);">Open-Source</span>
            <span class="leaderboard-label" style="background-color: rgba(117, 209, 215, 0.1);">Proprietary</span>
          </div>

          <table>
            <tr style="background-color: rgba(122, 122, 122, 0.15);">
                <td class="js-sort-number" style="text-align: left;"><strong>Model</strong></td>
                <td class="js-sort-number"><strong>Overall</strong></td>
                <td class="js-sort-number" style="text-decoration: overline;"><strong>R</strong></td>
                <td class="js-sort-number"><strong>VR</strong></td>
                <td class="js-sort-number"><strong>Loc</strong></td>
                <td class="js-sort-number"><strong>OCR</strong></td>
                <td class="js-sort-number"><strong>Count</strong></td>
                <td class="js-sort-number"><strong>HLN</strong></td>
                <td class="js-sort-number"><strong>IR</strong></td>
                <td class="js-sort-number"><strong>3D</strong></td>
                <td class="js-sort-number"><strong>VC</strong></td>
                <td class="js-sort-number"><strong>VG</strong></td>
                <td class="js-sort-number"><strong>DU</strong></td>
                <td class="js-sort-number"><strong>AR</strong></td>
                <td class="js-sort-number"><strong>PLP</strong></td>
                <td class="js-sort-number"><strong>I2IT</strong></td>
                <td class="js-sort-number"><strong>RR</strong></td>
                <td class="js-sort-number"><strong>IQT</strong></td>
                <td class="js-sort-number"><strong>Emo</strong></td>
            </tr>
            <tr style="background-color: rgba(122, 122, 122, 0.15);">
                <td></td>
                <td class="js-sort-number"><strong>Overall*</strong></td>
                <td class="js-sort-number" style="text-decoration: overline;"><strong>R*</strong></td>
                <td class="js-sort-number"><strong>VI</strong></td>
                <td class="js-sort-number"><strong>MemU</strong></td>
                <td class="js-sort-number"><strong>VPU</strong></td>
                <td class="js-sort-number"><strong>AND</strong></td>
                <td class="js-sort-number"><strong>KD</strong></td>
                <td class="js-sort-number"><strong>VCR</strong></td>
                <td class="js-sort-number"><strong>IEJ</strong></td>
                <td class="js-sort-number"><strong>MIA</strong></td>
                <td class="js-sort-number"><strong>CIM</strong></td>
                <td class="js-sort-number"><strong>TU</strong></td>
                <td class="js-sort-number"><strong>VP</strong></td>
                <td class="js-sort-number"><strong>MedU</strong></td>
                <td class="js-sort-number"><strong>AUD</strong></td>
                <td class="js-sort-number"><strong>DKR</strong></td>
                <td class="js-sort-number"><strong>EA</strong></td>
                <td class="js-sort-number"><strong>GN</strong></td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td style="text-align: left;"><strong>Frequency Guess</strong></td>
                <td>31.7</td>
                <td>26.1</td>
                <td>30.0</td>
                <td>28.2</td>
                <td>30.4</td>
                <td>28.2</td>
                <td>43.4</td>
                <td>29.9</td>
                <td>26.5</td>
                <td>28.2</td>
                <td>29.1</td>
                <td>37.6</td>
                <td>30.0</td>
                <td>29.4</td>
                <td>30.8</td>
                <td>33.5</td>
                <td>18.0</td>
                <td>30.1</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td></td>
                <td>32.2</td>
                <td>25.9</td>
                <td>52.1</td>
                <td>32.8</td>
                <td>29.3</td>
                <td>44.4</td>
                <td>33.7</td>
                <td>27.0</td>
                <td>30.0</td>
                <td>46.5</td>
                <td>28.5</td>
                <td>29.1</td>
                <td>29.5</td>
                <td>30.9</td>
                <td>29.7</td>
                <td>29.4</td>
                <td>28.0</td>
                <td>29.0</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td style="text-align: left;"><strong>Random Guess</strong></td>
                <td>28.5</td>
                <td>30.0</td>
                <td>27.1</td>
                <td>28.1</td>
                <td>27.2</td>
                <td>25.0</td>
                <td>41.6</td>
                <td>24.3</td>
                <td>25.5</td>
                <td>25.0</td>
                <td>24.8</td>
                <td>30.3</td>
                <td>25.4</td>
                <td>26.6</td>
                <td>21.2</td>
                <td>33.4</td>
                <td>10.5</td>
                <td>25.4</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td></td>
                <td>28.9</td>
                <td>29.9</td>
                <td>50.8</td>
                <td>25.5</td>
                <td>31.4</td>
                <td>36.5</td>
                <td>32.2</td>
                <td>28.0</td>
                <td>25.0</td>
                <td>48.5</td>
                <td>26.8</td>
                <td>27.0</td>
                <td>28.8</td>
                <td>27.8</td>
                <td>26.8</td>
                <td>25.4</td>
                <td>27.5</td>
                <td>24.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/OpenGVLab/InternVL/">
                    <b>InternVL-Chat-v1.2-34B</b>
                 </a>
                </td>
                <td><b>63.4</b></td>
                <td><b>5.7</b></td>
                <td>81.3</td>
                <td>59.4</td>
                <td>60.5</td>
                <td><b>66.4</b></td>
                <td><b>82.4</b></td>
                <td>56.3</td>
                <td>45.5</td>
                <td>82.3</td>
                <td>49.4</td>
                <td>68.3</td>
                <td>52.6</td>
                <td>37.4</td>
                <td>32.8</td>
                <td>55.0</td>
                <td>84.0</td>
                <td>48.7</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td><b>58.2</b></td>
                <td><b>5.7</b></td>
                <td><b>61.5</b></td>
                <td>62.5</td>
                <td>58.2</td>
                <td>57.0</td>
                <td>62.2</td>
                <td>76.0</td>
                <td>31.0</td>
                <td><b>82.8</b></td>
                <td>56.8</td>
                <td>45.2</td>
                <td>41.8</td>
                <td>71.8</td>
                <td>57.8</td>
                <td>49.4</td>
                <td>74.5</td>
                <td>41.2</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td style="text-align: left;">
                  <a href="https://github.com/QwenLM/Qwen-VL?tab=readme-ov-file#qwen-vl-plus">
                    <b>Qwen-VL-Plus</b>
                 </a>
                </td>
                <td>62.3</td>
                <td>6.7</td>
                <td>82.6</td>
                <td>55.3</td>
                <td>65.6</td>
                <td>61.1</td>
                <td>69.9</td>
                <td>40.7</td>
                <td>46.5</td>
                <td><b>86.5</b></td>
                <td>43.6</td>
                <td><b>77.3</b></td>
                <td>53.4</td>
                <td>43.1</td>
                <td><b>37.8</b></td>
                <td>53.0</td>
                <td><b>84.5</b></td>
                <td>41.6</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td></td>
                <td>56.6</td>
                <td>6.8</td>
                <td>50.3</td>
                <td>61.0</td>
                <td><b>67.5</b></td>
                <td>58.8</td>
                <td>55.3</td>
                <td>76.5</td>
                <td>31.8</td>
                <td>81.5</td>
                <td>61.3</td>
                <td><b>45.5</b></td>
                <td>33.7</td>
                <td>73.3</td>
                <td>59.5</td>
                <td>46.8</td>
                <td><b>85.0</b></td>
                <td>32.6</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td style="text-align: left;">
                  <a href="https://openai.com/contributions/gpt-4v">
                    <b>GPT-4V</b>
                 </a>
                </td>
                <td>62.0</td>
                <td>8.3</td>
                <td><b>85.3</b></td>
                <td>55.6</td>
                <td><b>68.0</b></td>
                <td>51.6</td>
                <td>69.6</td>
                <td>44.9</td>
                <td>42.0</td>
                <td>80.3</td>
                <td>25.0</td>
                <td>69.8</td>
                <td>47.7</td>
                <td><b>48.2</b></td>
                <td>31.8</td>
                <td>52.5</td>
                <td>80.0</td>
                <td>45.1</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td style="text-align: left;"></td>
                <td>55.5</td>
                <td>8.6</td>
                <td>47.9</td>
                <td>61.0</td>
                <td>60.2</td>
                <td>51.4</td>
                <td>53.6</td>
                <td>73.0</td>
                <td>43.4</td>
                <td>70.2</td>
                <td>55.2</td>
                <td>44.6</td>
                <td><b>53.3</b></td>
                <td>74.0</td>
                <td>55.6</td>
                <td><b>53.4</b></td>
                <td>80.9</td>
                <td>39.7</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td style="text-align: left;">
                  <a href="https://labelbox.com/product/model/foundry-models/google-gemini-pro-vision/">
                    <b>GeminiProVision</b>
                 </a>
                </td>
                <td>61.6</td>
                <td>8.3</td>
                <td>84.7</td>
                <td>43.6</td>
                <td>59.5</td>
                <td>56.4</td>
                <td>65.9</td>
                <td><b>68.4</b></td>
                <td>45.2</td>
                <td>80.1</td>
                <td>33.0</td>
                <td>71.6</td>
                <td><b>57.4</b></td>
                <td>40.3</td>
                <td>31.5</td>
                <td>58.5</td>
                <td>11.0</td>
                <td><b>55.2</b></td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td></td>
                <td>55.1</td>
                <td>8.5</td>
                <td>47.5</td>
                <td>75.8</td>
                <td>50.9</td>
                <td>47.4</td>
                <td>49.5</td>
                <td><b>86.5</b></td>
                <td>35.0</td>
                <td>70.2</td>
                <td>33.3</td>
                <td>40.5</td>
                <td>46.0</td>
                <td><b>82.6</b></td>
                <td><b>59.5</b></td>
                <td>49.2</td>
                <td>74.5</td>
                <td>33.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">
                    <b>LLaVA-NEXT-34B</b>
                 </a>
                </td>
                <td>60.8</td>
                <td>7.5</td>
                <td>76.7</td>
                <td><b>61.0</b></td>
                <td>64.1</td>
                <td>66.3</td>
                <td>70.1</td>
                <td>38.8</td>
                <td>48.5</td>
                <td>85.9</td>
                <td><b>56.2</b></td>
                <td>69.1</td>
                <td>50.6</td>
                <td>41.9</td>
                <td>22.8</td>
                <td>54.9</td>
                <td>76.5</td>
                <td>50.3</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>56.3</td>
                <td>7.5</td>
                <td>57.8</td>
                <td>55.5</td>
                <td>57.2</td>
                <td><b>61.2</b></td>
                <td><b>62.7</b></td>
                <td>75.0</td>
                <td>22.2</td>
                <td>77.8</td>
                <td>43.0</td>
                <td>45.4</td>
                <td>40.2</td>
                <td>61.9</td>
                <td>55.1</td>
                <td>48.1</td>
                <td>80.0</td>
                <td><b>41.4</b></td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/InternLM/InternLM-XComposer">
                    <b>XComposer2</b>
                 </a>   
                </td>
                <td>55.7</td>
                <td>11.7</td>
                <td>75.3</td>
                <td>47.9</td>
                <td>43.9</td>
                <td>51.0</td>
                <td>69.5</td>
                <td>32.4</td>
                <td>40.5</td>
                <td>73.7</td>
                <td>42.6</td>
                <td>62.0</td>
                <td>46.3</td>
                <td>43.9</td>
                <td>31.5</td>
                <td>50.5</td>
                <td>8.0</td>
                <td>53.6</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>50.0</td>
                <td>11.7</td>
                <td>52.6</td>
                <td>71.2</td>
                <td>56.1</td>
                <td>56.2</td>
                <td>41.5</td>
                <td>83.0</td>
                <td><b>43.8</b></td>
                <td>80.8</td>
                <td>61.2</td>
                <td>36.6</td>
                <td>36.3</td>
                <td>53.5</td>
                <td>48.8</td>
                <td>43.8</td>
                <td>50.5</td>
                <td>29.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/salesforce/LAVIS/tree/main/projects/blip2">
                    <b>BLIP2</b>
                 </a>  
                </td>
                <td>54.8</td>
                <td>12.8</td>
                <td>75.1</td>
                <td>54.1</td>
                <td>48.1</td>
                <td>29.8</td>
                <td>66.1</td>
                <td>27.4</td>
                <td>47.8</td>
                <td>78.7</td>
                <td>33.5</td>
                <td>43.0</td>
                <td>51.1</td>
                <td>46.1</td>
                <td>28.2</td>
                <td>53.0</td>
                <td>14.0</td>
                <td>43.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;"></td>
                <td>49.1</td>
                <td>12.8</td>
                <td>55.6</td>
                <td>76.2</td>
                <td>39.8</td>
                <td>43.7</td>
                <td>60.2</td>
                <td>77.0</td>
                <td>29.8</td>
                <td>62.8</td>
                <td><b>73.0</b></td>
                <td>42.7</td>
                <td>43.2</td>
                <td>60.1</td>
                <td>44.6</td>
                <td>37.0</td>
                <td>80.5</td>
                <td>33.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/01-ai/Yi-VL-34B">
                    <b>Yi-VL-34B</b>
                 </a> 
                </td>
                <td>54.2</td>
                <td>14.3</td>
                <td>74.6</td>
                <td>47.0</td>
                <td>58.0</td>
                <td>59.4</td>
                <td>65.8</td>
                <td>28.8</td>
                <td>38.8</td>
                <td>74.0</td>
                <td>41.5</td>
                <td>56.4</td>
                <td>40.4</td>
                <td>38.4</td>
                <td>19.5</td>
                <td>51.7</td>
                <td>68.5</td>
                <td>39.7</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;"></td>
                <td>48.6</td>
                <td>14.3</td>
                <td>51.3</td>
                <td>56.2</td>
                <td>61.2</td>
                <td>52.4</td>
                <td>49.5</td>
                <td>71.5</td>
                <td>25.5</td>
                <td>66.0</td>
                <td>48.0</td>
                <td>39.2</td>
                <td>32.0</td>
                <td>59.6</td>
                <td>48.2</td>
                <td>44.3</td>
                <td>57.0</td>
                <td>32.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/echo840/Monkey-Chat">
                    <b>Monkey-Chat</b>
                 </a> 
                </td>
                <td>53.4</td>
                <td>15.5</td>
                <td>79.0</td>
                <td>40.1</td>
                <td>51.0</td>
                <td>43.6</td>
                <td>63.1</td>
                <td>26.8</td>
                <td>46.5</td>
                <td>68.9</td>
                <td>27.5</td>
                <td>51.1</td>
                <td>49.3</td>
                <td>32.2</td>
                <td>29.5</td>
                <td><b>61.8</b></td>
                <td>11.0</td>
                <td>45.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>46.0</td>
                <td>15.8</td>
                <td>55.3</td>
                <td>69.5</td>
                <td>43.6</td>
                <td>44.6</td>
                <td>36.3</td>
                <td>85.5</td>
                <td>26.0</td>
                <td>58.8</td>
                <td>61.7</td>
                <td>36.8</td>
                <td>33.3</td>
                <td>68.0</td>
                <td>43.6</td>
                <td>38.1</td>
                <td>46.0</td>
                <td>29.8</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/deepseek-ai/deepseek-vl-7b-base">
                    <b>DeepSeek-VL-7B</b>
                 </a> 
                </td>
                <td>53.2</td>
                <td>15.0</td>
                <td>75.6</td>
                <td>42.0</td>
                <td>61.1</td>
                <td>44.5</td>
                <td>60.6</td>
                <td>30.5</td>
                <td>47.2</td>
                <td>69.1</td>
                <td>38.4</td>
                <td>51.9</td>
                <td>44.8</td>
                <td>38.3</td>
                <td>23.5</td>
                <td>48.8</td>
                <td>37.0</td>
                <td>43.8</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>46.5</td>
                <td>15.2</td>
                <td>47.7</td>
                <td>59.8</td>
                <td>53.5</td>
                <td>45.4</td>
                <td>41.0</td>
                <td>41.0</td>
                <td>38.8</td>
                <td>35.0</td>
                <td>67.2</td>
                <td>33.1</td>
                <td>30.7</td>
                <td>69.7</td>
                <td>48.8</td>
                <td>36.4</td>
                <td>67.5</td>
                <td>36.8</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/01-ai/Yi-VL-6B">
                    <b>Yi-VL-6B</b>
                 </a> 
                </td>
                <td>53.2</td>
                <td>14.7</td>
                <td>73.5</td>
                <td>49.4</td>
                <td>53.1</td>
                <td>56.2</td>
                <td>63.9</td>
                <td>26.0</td>
                <td>43.5</td>
                <td>63.4</td>
                <td>42.1</td>
                <td>55.2</td>
                <td>43.8</td>
                <td>35.3</td>
                <td>26.8</td>
                <td>48.8</td>
                <td>47.0</td>
                <td>46.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>47.5</td>
                <td>14.5</td>
                <td>55.8</td>
                <td>54.5</td>
                <td>49.2</td>
                <td>53.0</td>
                <td>51.8</td>
                <td>65.5</td>
                <td>34.2</td>
                <td>52.0</td>
                <td>43.3</td>
                <td>37.6</td>
                <td>37.0</td>
                <td>60.6</td>
                <td>46.9</td>
                <td>40.2</td>
                <td>48.0</td>
                <td>34.8</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">
                    <b>LLaVA-NEXT-13B</b>
                 </a>
                </td>
                <td>53.0</td>
                <td>15.0</td>
                <td>74.0</td>
                <td>35.6</td>
                <td>51.8</td>
                <td>59.2</td>
                <td>63.6</td>
                <td>32.7</td>
                <td><b>50.0</b></td>
                <td>75.0</td>
                <td>44.6</td>
                <td>53.6</td>
                <td>46.5</td>
                <td>34.0</td>
                <td>26.2</td>
                <td>50.0</td>
                <td>50.0</td>
                <td>44.5</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;"></td>
                <td>46.8</td>
                <td>14.9</td>
                <td>57.5</td>
                <td>55.0</td>
                <td>32.2</td>
                <td>49.6</td>
                <td>38.9</td>
                <td>47.0</td>
                <td>18.0</td>
                <td>36.5</td>
                <td>59.8</td>
                <td>38.9</td>
                <td>22.5</td>
                <td>55.8</td>
                <td>55.7</td>
                <td>38.5</td>
                <td>70.0</td>
                <td>41.0</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/PCIResearch/TransCore-M">
                    <b>TransCore-M</b>
                 </a>
                </td>
                <td>52.7</td>
                <td>13.1</td>
                <td>73.6</td>
                <td>40.5</td>
                <td>50.4</td>
                <td>54.5</td>
                <td>71.9</td>
                <td>27.5</td>
                <td>45.0</td>
                <td>75.6</td>
                <td>35.1</td>
                <td>45.3</td>
                <td>46.9</td>
                <td>38.3</td>
                <td>25.0</td>
                <td>53.2</td>
                <td>15.0</td>
                <td>46.3</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>46.9</td>
                <td>12.9</td>
                <td>55.6</td>
                <td><b>76.8</b></td>
                <td>51.9</td>
                <td>43.7</td>
                <td>38.6</td>
                <td>85.5</td>
                <td>34.2</td>
                <td>52.8</td>
                <td>65.8</td>
                <td>29.7</td>
                <td>28.8</td>
                <td>61.1</td>
                <td>46.5</td>
                <td>38.4</td>
                <td>39.5</td>
                <td>35.6</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/Qwen/Qwen-VL-Chat">
                    <b>QWen-VL-Chat</b>
                 </a>
                </td>
                <td>52.5</td>
                <td>16.0</td>
                <td>77.5</td>
                <td>33.7</td>
                <td>46.9</td>
                <td>46.7</td>
                <td>63.9</td>
                <td>27.5</td>
                <td>45.0</td>
                <td>73.0</td>
                <td>26.5</td>
                <td>51.5</td>
                <td>50.9</td>
                <td>32.7</td>
                <td>30.5</td>
                <td>57.4</td>
                <td>13.5</td>
                <td>45.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>45.4</td>
                <td>16.3</td>
                <td>50.9</td>
                <td>74.2</td>
                <td>42.4</td>
                <td>40.2</td>
                <td>35.9</td>
                <td>86.0</td>
                <td>30.0</td>
                <td>49.2</td>
                <td>58.3</td>
                <td>37.3</td>
                <td>30.8</td>
                <td>67.1</td>
                <td>45.4</td>
                <td>35.6</td>
                <td>55.0</td>
                <td>30.2</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td style="text-align: left;">
                  <a href="https://www.anthropic.com/news/claude-3-family">
                    <b>Claude3V-Haiku</b>
                 </a>
                </td>
                <td>52.2</td>
                <td>17.7</td>
                <td>74.3</td>
                <td>44.8</td>
                <td>54.4</td>
                <td>51.1</td>
                <td>63.6</td>
                <td>34.6</td>
                <td>38.2</td>
                <td>67.6</td>
                <td>26.9</td>
                <td>69.8</td>
                <td>46.2</td>
                <td>35.5</td>
                <td>22.8</td>
                <td>50.0</td>
                <td>59.5</td>
                <td>35.2</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
                <td></td>
                <td>46.4</td>
                <td>17.7</td>
                <td>42.9</td>
                <td>53.8</td>
                <td>43.2</td>
                <td>41.2</td>
                <td>53.3</td>
                <td>70.5</td>
                <td>31.5</td>
                <td>34.8</td>
                <td>52.5</td>
                <td>35.9</td>
                <td>34.2</td>
                <td>62.7</td>
                <td>34.1</td>
                <td>40.4</td>
                <td>54.5</td>
                <td>35.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/InternLM/InternLM-XComposer">
                    <b>XComposer</b>
                 </a>
                </td>
                <td>52.1</td>
                <td>17.1</td>
                <td>75.4</td>
                <td>40.4</td>
                <td>44.1</td>
                <td>39.9</td>
                <td>66.5</td>
                <td>49.7</td>
                <td>47.0</td>
                <td>72.1</td>
                <td>27.2</td>
                <td>36.6</td>
                <td>47.9</td>
                <td>39.6</td>
                <td>24.5</td>
                <td>50.2</td>
                <td>14.0</td>
                <td>45.9</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;"></td>
                <td>45.6</td>
                <td>17.3</td>
                <td>53.4</td>
                <td>63.8</td>
                <td>40.6</td>
                <td>43.4</td>
                <td>42.3</td>
                <td>78.0</td>
                <td>29.0</td>
                <td>66.2</td>
                <td>52.3</td>
                <td>33.1</td>
                <td>28.3</td>
                <td>55.6</td>
                <td>40.8</td>
                <td>39.3</td>
                <td>38.5</td>
                <td>34.2</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/X-PLUG/mPLUG-Owl">
                    <b>mPLUG-Owl2</b>
                 </a>
                </td>
                <td>52.0</td>
                <td>17.3</td>
                <td>76.5</td>
                <td>45.8</td>
                <td>44.5</td>
                <td>47.6</td>
                <td>63.4</td>
                <td>27.6</td>
                <td>45.2</td>
                <td>66.6</td>
                <td>33.0</td>
                <td>42.4</td>
                <td>45.2</td>
                <td>41.6</td>
                <td>25.5</td>
                <td>52.0</td>
                <td>18.0</td>
                <td>42.0</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>45.0</td>
                <td>17.5</td>
                <td>58.5</td>
                <td>59.0</td>
                <td>40.1</td>
                <td>49.4</td>
                <td>32.9</td>
                <td>85.5</td>
                <td>30.0</td>
                <td>55.0</td>
                <td>57.7</td>
                <td>31.9</td>
                <td>27.3</td>
                <td>63.4</td>
                <td>45.5</td>
                <td>38.1</td>
                <td>35.0</td>
                <td>27.8</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/RBDash-Team/rbdash-v1-13b">
                    <b>RBDash-v1-13B</b>
                 </a>
                </td>
                <td>51.8</td>
                <td>15.7</td>
                <td>72.2</td>
                <td>42.2</td>
                <td>53.6</td>
                <td>51.6</td>
                <td>66.6</td>
                <td>26.3</td>
                <td>40.8</td>
                <td>75.5</td>
                <td>36.9</td>
                <td>48.1</td>
                <td>47.1</td>
                <td>38.3</td>
                <td>22.5</td>
                <td>55.9</td>
                <td>14.0</td>
                <td>43.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>46.1</td>
                <td>15.3</td>
                <td>57.1</td>
                <td>67.5</td>
                <td>51.4</td>
                <td>45.7</td>
                <td>33.2</td>
                <td>78.0</td>
                <td>39.0</td>
                <td>32.0</td>
                <td>64.2</td>
                <td>31.6</td>
                <td>25.5</td>
                <td>59.3</td>
                <td>46.3</td>
                <td>38.1</td>
                <td>53.5</td>
                <td>32.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/liuhaotian/llava-v1.5-13b">
                    <b>LLaVA-v1.5-13B</b>
                 </a>
                </td>
                <td>51.7</td>
                <td>15.3</td>
                <td>73.8</td>
                <td>38.8</td>
                <td>51.8</td>
                <td>55.1</td>
                <td>65.8</td>
                <td>27.2</td>
                <td>39.8</td>
                <td>70.4</td>
                <td>37.4</td>
                <td>45.7</td>
                <td>46.6</td>
                <td>37.6</td>
                <td>28.0</td>
                <td>58.2</td>
                <td>13.5</td>
                <td>45.3</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>45.7</td>
                <td>15.2</td>
                <td>58.1</td>
                <td>66.0</td>
                <td>43.9</td>
                <td>48.3</td>
                <td>31.4</td>
                <td>79.0</td>
                <td>35.8</td>
                <td>28.5</td>
                <td>62.5</td>
                <td>33.3</td>
                <td>27.5</td>
                <td>58.6</td>
                <td>46.6</td>
                <td>39.4</td>
                <td>40.5</td>
                <td>37.5</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/THUDM/cogvlm-chat-hf">
                    <b>CogVLM-Chat</b>
                 </a>
                </td>
                <td>51.6</td>
                <td>17.5</td>
                <td>77.7</td>
                <td>24.7</td>
                <td>48.5</td>
                <td>49.8</td>
                <td>66.0</td>
                <td>26.1</td>
                <td>42.2</td>
                <td>69.8</td>
                <td>28.8</td>
                <td>49.1</td>
                <td>46.3</td>
                <td>33.2</td>
                <td>23.8</td>
                <td>61.6</td>
                <td>14.0</td>
                <td>50.3</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>44.2</td>
                <td>17.9</td>
                <td>52.4</td>
                <td>75.5</td>
                <td>39.8</td>
                <td>43.4</td>
                <td>28.2</td>
                <td>82.0</td>
                <td>28.0</td>
                <td>70.8</td>
                <td>45.8</td>
                <td>35.5</td>
                <td>28.3</td>
                <td>65.9</td>
                <td>44.9</td>
                <td>36.9</td>
                <td>48.0</td>
                <td>29.9</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/Lin-Chen/ShareGPT4V-7B">
                    <b>ShareGPT4V-7B</b>
                </td>
                <td>51.5</td>
                <td>16.4</td>
                <td>74.2</td>
                <td>36.0</td>
                <td>47.8</td>
                <td>50.9</td>
                <td>62.4</td>
                <td>27.8</td>
                <td>45.2</td>
                <td>71.6</td>
                <td>35.4</td>
                <td>47.9</td>
                <td>46.2</td>
                <td>39.2</td>
                <td>21.8</td>
                <td>59.8</td>
                <td>14.0</td>
                <td>44.3</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>45.1</td>
                <td>16.4</td>
                <td>54.5</td>
                <td>70.5</td>
                <td>47.1</td>
                <td>48.2</td>
                <td>26.3</td>
                <td>83.0</td>
                <td>27.8</td>
                <td>38.0</td>
                <td>64.3</td>
                <td>32.1</td>
                <td>30.0</td>
                <td>60.8</td>
                <td>46.1</td>
                <td>38.9</td>
                <td>42.0</td>
                <td>28.9</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td style="text-align: left;">
                <a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">
                  <b>LLaVA-NEXT-7B</b>
               </a>
              </td>
                <td>51.1</td>
                <td>18.1</td>
                <td>73.3</td>
                <td>29.5</td>
                <td>52.0</td>
                <td>56.8</td>
                <td>59.9</td>
                <td>28.7</td>
                <td>43.2</td>
                <td>69.8</td>
                <td>37.0</td>
                <td>49.7</td>
                <td>47.9</td>
                <td>32.6</td>
                <td>22.8</td>
                <td>49.0</td>
                <td>47.5</td>
                <td>48.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>44.6</td>
                <td>18.0</td>
                <td>57.8</td>
                <td>54.0</td>
                <td>38.5</td>
                <td>44.3</td>
                <td>34.6</td>
                <td>42.5</td>
                <td>18.8</td>
                <td>32.5</td>
                <td>67.8</td>
                <td>39.1</td>
                <td>23.3</td>
                <td>55.5</td>
                <td>53.5</td>
                <td>37.0</td>
                <td>65.0</td>
                <td>31.6</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/xtuner/llava-v1.5-13b-xtuner">
                    <b>LLaVA-v1.5-13B-XTuner</b>
                 </a>
                </td>
                <td>51.1</td>
                <td>16.8</td>
                <td>72.5</td>
                <td>40.7</td>
                <td>46.8</td>
                <td>54.1</td>
                <td>66.5</td>
                <td>26.4</td>
                <td>47.5</td>
                <td>68.8</td>
                <td>35.6</td>
                <td>47.0</td>
                <td>44.2</td>
                <td>38.3</td>
                <td>26.0</td>
                <td>52.4</td>
                <td>14.0</td>
                <td>51.0</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>45.1</td>
                <td>16.5</td>
                <td>54.4</td>
                <td>66.5</td>
                <td>47.9</td>
                <td>52.0</td>
                <td>28.8</td>
                <td>82.0</td>
                <td>39.2</td>
                <td>37.0</td>
                <td>56.8</td>
                <td>28.3</td>
                <td>28.3</td>
                <td>49.1</td>
                <td>44.4</td>
                <td>37.3</td>
                <td>33.5</td>
                <td>40.9</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/xtuner/llava-internlm2-7b">
                    <b>LLaVA-InternLM2-7B</b>
                 </a>
                </td>
                <td>50.8</td>
                <td>17.5</td>
                <td>73.3</td>
                <td>38.9</td>
                <td>49.5</td>
                <td>51.8</td>
                <td>67.8</td>
                <td>27.7</td>
                <td>49.5</td>
                <td>66.4</td>
                <td>36.9</td>
                <td>37.7</td>
                <td>43.7</td>
                <td>35.1</td>
                <td>14.2</td>
                <td>58.0</td>
                <td>0.0</td>
                <td>51.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>44.4</td>
                <td>17.4</td>
                <td>52.3</td>
                <td>62.5</td>
                <td>45.1</td>
                <td>57.2</td>
                <td>35.2</td>
                <td>83.0</td>
                <td>34.2</td>
                <td>55.8</td>
                <td>58.2</td>
                <td>26.8</td>
                <td>18.5</td>
                <td>57.8</td>
                <td>45.1</td>
                <td>33.7</td>
                <td>35.5</td>
                <td>35.2</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/xtuner/llava-v1.5-7b-xtuner">
                    <b>LLaVA-v1.5-7B-XTuner</b>
                 </a>
                </td>
                <td>50.2</td>
                <td>19.5</td>
                <td>72.5</td>
                <td>41.1</td>
                <td>46.0</td>
                <td>49.9</td>
                <td>62.1</td>
                <td>26.0</td>
                <td>45.5</td>
                <td>66.4</td>
                <td>35.3</td>
                <td>42.8</td>
                <td>45.8</td>
                <td>42.5</td>
                <td>25.5</td>
                <td>53.9</td>
                <td>11.5</td>
                <td>44.2</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>43.9</td>
                <td>19.3</td>
                <td>60.1</td>
                <td>56.5</td>
                <td>42.6</td>
                <td>47.2</td>
                <td>28.4</td>
                <td>80.5</td>
                <td>32.2</td>
                <td>41.2</td>
                <td>63.2</td>
                <td>29.9</td>
                <td>24.2</td>
                <td>52.5</td>
                <td>43.4</td>
                <td>37.2</td>
                <td>32.0</td>
                <td>30.5</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/Lin-Chen/ShareCaptioner">
                    <b>SharedCaptioner</b>
                 </a>
                </td>
                <td>49.9</td>
                <td>19.6</td>
                <td>72.8</td>
                <td>41.8</td>
                <td>47.8</td>
                <td>46.2</td>
                <td>63.1</td>
                <td>27.0</td>
                <td>44.2</td>
                <td>61.9</td>
                <td>27.0</td>
                <td>39.5</td>
                <td>46.7</td>
                <td>33.5</td>
                <td>25.0</td>
                <td>59.5</td>
                <td>14.5</td>
                <td>39.9</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>43.2</td>
                <td>19.5</td>
                <td>55.1</td>
                <td>53.8</td>
                <td>45.4</td>
                <td>38.3</td>
                <td>33.6</td>
                <td>82.5</td>
                <td>20.2</td>
                <td>57.8</td>
                <td>56.8</td>
                <td>32.6</td>
                <td>28.7</td>
                <td>59.4</td>
                <td>44.7</td>
                <td>38.4</td>
                <td>45.0</td>
                <td>29.6</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/xtuner/llava-internlm-7b">
                    <b>LLaVA-InternLM-7B</b>
                 </a> 
                </td>
                <td>49.7</td>
                <td>19.6</td>
                <td>70.1</td>
                <td>38.7</td>
                <td>47.6</td>
                <td>46.0</td>
                <td>62.0</td>
                <td>25.5</td>
                <td>42.0</td>
                <td>65.0</td>
                <td>26.5</td>
                <td>43.9</td>
                <td>45.6</td>
                <td>38.3</td>
                <td>25.0</td>
                <td>52.4</td>
                <td>14.0</td>
                <td>47.0</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>43.9</td>
                <td>19.3</td>
                <td>57.5</td>
                <td>58.2</td>
                <td>45.6</td>
                <td>46.5</td>
                <td>33.2</td>
                <td>75.5</td>
                <td>33.0</td>
                <td>57.0</td>
                <td>59.7</td>
                <td>28.0</td>
                <td>27.3</td>
                <td>52.0</td>
                <td>42.2</td>
                <td>38.1</td>
                <td>46.5</td>
                <td>37.6</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://huggingface.co/liuhaotian/llava-v1.5-7b">
                    <b>LLaVA-v1.5-7B</b>
                 </a> 
                </td>
                <td>49.5</td>
                <td>20.3</td>
                <td>72.8</td>
                <td>34.3</td>
                <td>45.0</td>
                <td>47.5</td>
                <td>61.6</td>
                <td>26.1</td>
                <td>44.8</td>
                <td>68.1</td>
                <td>34.0</td>
                <td>40.8</td>
                <td>46.6</td>
                <td>36.0</td>
                <td>22.2</td>
                <td>58.0</td>
                <td>12.5</td>
                <td>42.5</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>43.1</td>
                <td>20.3</td>
                <td>57.6</td>
                <td>70.5</td>
                <td>33.3</td>
                <td>49.1</td>
                <td>31.6</td>
                <td>81.0</td>
                <td>27.8</td>
                <td>37.5</td>
                <td>62.3</td>
                <td>31.7</td>
                <td>27.5</td>
                <td>56.8</td>
                <td>45.1</td>
                <td>35.6</td>
                <td>42.5</td>
                <td>20.4</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/OpenGVLab/LLaMA-Adapter">
                    <b>LLaMA-Adapter-v2-7B</b>
                 </a> 
                </td>
                <td>40.4</td>
                <td>27.5</td>
                <td>62.3</td>
                <td>32.5</td>
                <td>35.0</td>
                <td>30.1</td>
                <td>46.5</td>
                <td>24.1</td>
                <td>33.8</td>
                <td>34.8</td>
                <td>25.2</td>
                <td>30.2</td>
                <td>43.9</td>
                <td>33.1</td>
                <td>18.2</td>
                <td>44.9</td>
                <td>11.0</td>
                <td>36.0</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>34.1</td>
                <td>27.4</td>
                <td>36.4</td>
                <td>40.5</td>
                <td>33.8</td>
                <td>30.4</td>
                <td>34.9</td>
                <td>71.0</td>
                <td>33.2</td>
                <td>42.2</td>
                <td>35.8</td>
                <td>31.1</td>
                <td>25.8</td>
                <td>52.0</td>
                <td>29.1</td>
                <td>32.0</td>
                <td>25.0</td>
                <td>29.9</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td style="text-align: left;">
                  <a href="https://github.com/THUDM/VisualGLM-6B">
                    <b>VisualGLM-6B</b>
                 </a>
                </td>
                <td>38.6</td>
                <td>27.1</td>
                <td>55.0</td>
                <td>33.1</td>
                <td>33.8</td>
                <td>31.1</td>
                <td>39.2</td>
                <td>26.0</td>
                <td>36.8</td>
                <td>40.5</td>
                <td>31.1</td>
                <td>39.1</td>
                <td>39.2</td>
                <td>32.4</td>
                <td>26.8</td>
                <td>43.8</td>
                <td>14.0</td>
                <td>33.1</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
                <td></td>
                <td>33.9</td>
                <td>27.0</td>
                <td>28.9</td>
                <td>44.8</td>
                <td>27.1</td>
                <td>34.5</td>
                <td>35.2</td>
                <td>65.0</td>
                <td>28.0</td>
                <td>35.8</td>
                <td>48.2</td>
                <td>30.8</td>
                <td>23.5</td>
                <td>44.0</td>
                <td>26.2</td>
                <td>29.6</td>
                <td>37.5</td>
                <td>21.1</td>
            </tr>
        </table>  
        </div>
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Taskonomy Analysis</h2>
        <div class="content has-text-justified">
          <p>
            Thanks to the extensive coverage of tasks in the MMTBench, we can evaluate the multimodal performance of LVLMs on a task map. In this way, the roles of different tasks in multimodal capability can be systematically interpreted by analyzing relationships between tasks in the map.
            Based on the task map, we find that LVLMs obtain a more consistent performance ranking on tasks closer to each other.
            Besides, our task map can also be used to discover Out-of-Domain (OoD) tasks and In-domain tasks.
          </p>
          <p>
            The OoD tasks mean tasks that the current model struggles to handle. 
            Discovering OoD tasks can provide insights for future evaluation efforts and the development of stronger LVLMs. 
            To this end, we conduct hierarchical clustering on the task map to find OoD tasks. 
            We use two criteria to identify clusters containing OoD tasks. 
            First, LVLMs would achieve poor performance on OoD tasks. 
            Second, the performance of LVLMs on OoD tasks would be inconsistent with the overall multimodal score in the leaderboard because LVLMs with competitive overall scores would even fail to solve OoD tasks.
            In this way, we can see that clusters 8, 9, and 11 achieve low multimodal accuracy and ranking correlation. 
            From these clusters, we find that current multimodal large models lack the ability to perform fine-grained
            visual cognition and understanding of positional and spatial relationships, such as localization and detection tasks. 
            Moreover, they exhibit poor performance in tasks related to new data structures or types of images, showing a lack of proficiency in handling tasks related to GUI and special data structures like tables.
          </p>
          <p>
            In-domain tasks are tasks that most current multimodal large models can handle correctly. Discovering in-domain tasks guides the commercial application of LVLMs in specific scenarios. Different from OoD tasks, we identify in-domain tasks by looking for clusters with large ranking correlation and high multimodal accuracy. 
            In this way, we can see that clusters 2, 3, and 10 achieve relatively high accuracy and large ranking correlation. We observe that current multimodal large models possess strong high-level visual comprehension capabilities, enabling them to effectively handle visual recognition tasks, even when dealing with specialized images such as 
            medical images. Moreover, they benefit from the powerful LLMs to accurately describe images.
          </p>
        </div>
        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
           
           
              
                <div class="content has-text-centered">
                  <img src="static/images/task_map.png" alt="error distribution" width="60%">
                  <p> Visualization of task maps and hierarchical clustering with task map.</p>
               
                </div>
             
                <div class="content has-text-centered">
                  <img src="static/images/model_performance.png" alt="arithmetic reasoning" width="60%"/>
                  <p> Visualization of model performance on different tasks. Different colours signify the respective categories formed after
                    clustering, arranged from left to right, starting from the first category through to the twelfth.</p>
                </div>
             
           
            
          </div>
        </div>
       
        <!-- <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_distribution_1.Jpeg" alt="algebraic reasoning" width="45%"/>
              <p> Error distribution over 150 annotated GPT-4V errors.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_case_main_text_1_1.Jpeg" alt="arithmetic reasoning" width="45%"/>
              <p> A basic perceptual error, easy for humans but challenging for GPT-4V.</p>
            </div>
          </div>
        </div> -->
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Error Analysis</h2>
        <div class="content has-text-justified">
          <p>
            To analyze the error distribution of LVLMs on the MMTBench, we examined three LVLMs: GPT-4V, GeminiProVision, and InternVL-Chat-V1.2 (InternVL).
            In results, perception error stands out as the most common type of error across all models, with GPT-4V exhibiting a significantly lower perception error rate (51%) compared to GeminiProVision (76.9%) and InternVL (67.2%), indicating its superior performance in perception tasks.
            Reasoning error emerges as the second most prevalent error type, with InternVL having the highest reasoning error rate (14.8%), followed by GeminiProVision (10.4%) and GPT-4V (9.94%), highlighting the challenges all models face in complex reasoning tasks.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="static/images/error_distribution.png" alt="error distribution" width="60%">
          <p> Distribution of error types for GPT-4V, GeminiProVision and InternVL-Chat-V1.2.</p>
        </div>
        <!-- <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_distribution_1.Jpeg" alt="algebraic reasoning" width="45%"/>
              <p> Error distribution over 150 annotated GPT-4V errors.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_case_main_text_1_1.Jpeg" alt="arithmetic reasoning" width="45%"/>
              <p> A basic perceptual error, easy for humans but challenging for GPT-4V.</p>
            </div>
          </div>
        </div> -->
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="examples">Case Study</h2>
          <div class="image-row">
            <img src="static/images/error/error_26.png" alt="Image 1">
            <img src="static/images/error/error_32.png" alt="Image 2">
          </div>
          <p>
            Please see more cases in our paper for further discussions.
          </p>
      </div>
    </div>

  </div>
</section>
<!-- @PAN TODO: bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
     @misc{ying2024mmtbench,
      title={MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI}, 
      author={Kaining Ying and Fanqing Meng and Jin Wang and Zhiqian Li and Han Lin and Yue Yang and Hao Zhang and Wenbo Zhang and Yuqi Lin and Shuo Liu and Jiayi Lei and Quanfeng Lu and Runjian Chen and Peng Xu and Renrui Zhang and Haozhe Zhang and Peng Gao and Yali Wang and Yu Qiao and Ping Luo and Kaipeng Zhang and Wenqi Shao},
      year={2024},
      eprint={2404.16006},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
      }
</code></pre>
  </div>
</section>

<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://mmmu-benchmark.github.io/">MMMU</a>, <a href="https://mathvista.github.io/">MathVista</a> and <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->

</footer>
<script>
  function changeButtonText() {
    var button = document.getElementById('toggleButton');
    if (button.innerHTML.includes("Validation Set Leaderboard")) {
      button.innerHTML = "<b style='font-size: larger;'>Test Set Leaderboard</b> (Click to Switch)";
    } else {
      button.innerHTML = "<b style='font-size: larger;'>Validation Set Leaderboard</b> (Click to Switch)";
    }
  }
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');

    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

function sortTable(table, column, type, asc) {
    var tbody = table.tBodies[0];
    var rows = Array.from(tbody.rows);

    rows.sort(function(a, b) {
        var valA = a.cells[column].textContent;
        var valB = b.cells[column].textContent;

        if (type === 'number') {
            valA = parseFloat(valA);
            valB = parseFloat(valB);
        }

        return asc ? valA - valB : valB - valA;
    });

    rows.forEach(row => tbody.appendChild(row));
}

  // 切换表格的函数
  function toggleTables () {
      var table1 = document.getElementById('table1');
      var table2 = document.getElementById('table2');
      table1.classList.toggle('hidden');
      table2.classList.toggle('hidden');
  }

  document.getElementById('toggleButton').addEventListener('click', toggleTables);
  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'GPT-4V',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 // 设置X轴字体大小
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 // 设置标签文字大小
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });
  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Other " chart
    const data_Other   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' ↑';
  }
  .desc::after {
      content: ' ↓';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* 鼠标悬停时的阴影效果 */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>
</body>
</html>
